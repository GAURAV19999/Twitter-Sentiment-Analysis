{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import nltk libraries for NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk  import WordNetLemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#import seaborn for plotting\n",
    "import seaborn as sns\n",
    "\n",
    "#import libraries for model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the tweet data from csv file\n",
    "df = pd.read_csv(\"train_E6oV3lV.csv\",encoding = 'utf-8')\n",
    "test_tweets = pd.read_csv(\"test_tweets_anuFYb8.csv\",encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                              tweet\n",
       "0          0   @user when a father is dysfunctional and is s...\n",
       "1          0  @user @user thanks for #lyft credit i can't us...\n",
       "2          0                                bihday your majesty\n",
       "3          0  #model   i love u take with u all the time in ...\n",
       "4          0             factsguide: society now    #motivation\n",
       "...      ...                                                ...\n",
       "31957      0  ate @user isz that youuu?ðððððð...\n",
       "31958      0    to see nina turner on the airwaves trying to...\n",
       "31959      0  listening to sad songs on a monday morning otw...\n",
       "31960      1  @user #sikh #temple vandalised in in #calgary,...\n",
       "31961      0                   thank you @user for you follow  \n",
       "\n",
       "[31962 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop the id columm, it is irrelevant\n",
    "df.drop(columns = 'id',inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARIKA\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARIKA\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret input 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7af1e1121a46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'length'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpalette\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'PRGn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[1;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge, ax, **kwargs)\u001b[0m\n\u001b[0;32m   3167\u001b[0m ):\n\u001b[0;32m   3168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3169\u001b[1;33m     plotter = _BarPlotter(x, y, hue, data, order, hue_order,\n\u001b[0m\u001b[0;32m   3170\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3171\u001b[0m                           \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, seed, orient, color, palette, saturation, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[0;32m   1582\u001b[0m                  errwidth, capsize, dodge):\n\u001b[0;32m   1583\u001b[0m         \u001b[1;34m\"\"\"Initialize the plotter.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1584\u001b[1;33m         self.establish_variables(x, y, hue, data, orient,\n\u001b[0m\u001b[0;32m   1585\u001b[0m                                  order, hue_order, units)\n\u001b[0;32m   1586\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\categorical.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[1;34m(self, x, y, hue, data, orient, order, hue_order, units)\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                     \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Could not interpret input '{}'\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;31m# Figure out the plotting orientation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret input 'length'"
     ]
    }
   ],
   "source": [
    "sns.barplot('label','length',data = df,palette='PRGn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARIKA\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\inference.py:178: FutureWarning: Possible nested set at position 1\n",
      "  re.compile(obj)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Clean the tweets    \n",
    "df['cleaned_tweet'] = df['tweet'].replace(r'\\'|\\\"|\\,|\\.|\\?|\\+|\\-|\\/|\\=|\\(|\\)|\\n|\"', '', regex=True)\n",
    "df['cleaned_tweet'] = df['cleaned_tweet'].replace(\"  \", \" \")\n",
    "\n",
    "test_tweets['cleaned_tweet'] = test_tweets['tweet'].replace(r'\\'|\\\"|\\,|\\.|\\?|\\+|\\-|\\/|\\=|\\(|\\)|\\n|\"', '', regex=True)\n",
    "test_tweets['cleaned_tweet'] = test_tweets['cleaned_tweet'].replace(\"  \", \" \")\n",
    "\n",
    "words_remove = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\"lines\",\"re\",\"what\", \"there\",\"all\",\"we\",\n",
    "                \"one\",\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\"but\",\"is\",\"in\",\"a\",\"not\",\"with\",\"as\",\n",
    "                \"was\",\"if\",\"they\",\"are\",\"this\",\"and\",\"it\",\"have\",\"has\",\"from\",\"at\",\"my\",\"be\",\"by\",\"not\",\"that\",\"to\",\n",
    "                \"from\",\"com\",\"org\",\"like\",\"likes\",\"so\",\"said\",\"from\",\"what\",\"told\",\"over\",\"more\",\"other\",\n",
    "                \"have\",\"last\",\"with\",\"this\",\"that\",\"such\",\"when\",\"been\",\"says\",\"will\",\"also\",\"where\",\"why\",\n",
    "                \"would\",\"today\", \"in\", \"on\", \"you\", \"r\", \"d\", \"u\", \"hw\",\"wat\", \"oly\", \"s\", \"b\", \"ht\", \n",
    "                \"rt\", \"p\",\"the\",\"th\", \"n\", \"was\"]\n",
    "\n",
    "\n",
    "def cleantext(df, words_to_remove = words_remove): \n",
    "    ### dont change the original tweet\n",
    "    # remove emoticons form the tweets\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'<ed>','', regex = True)\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'\\B<U+.*>|<U+.*>\\B|<U+.*>','', regex = True)\n",
    "    \n",
    "    # convert tweets to lowercase\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].str.lower()\n",
    "    \n",
    "    #remove user mentions\n",
    "    #df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^(@\\w+)',\"\", regex=True)\n",
    "    \n",
    "    #remove 'user' in the beginning\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'(@user+)',\"\", regex=True)\n",
    "    \n",
    "    #remove_symbols\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[^a-zA-Z0-9]', \" \", regex=True)\n",
    "    \n",
    "    #remove punctuations \n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[[]!\"#$%\\'()\\*+,-./:;<=>?^_`{|}]+',\"\", regex = True)\n",
    "\n",
    "    #remove_URL(x):\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'https.*$', \"\", regex = True)\n",
    "\n",
    "    #remove 'amp' in the text\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'amp',\"\", regex = True)\n",
    "    \n",
    "    #remove words of length 1 or 2 \n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'\\b[a-zA-Z]{1,2}\\b','', regex=True)\n",
    "\n",
    "    #remove extra spaces in the tweet\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^\\s+|\\s+$',\" \", regex=True)\n",
    "     \n",
    "    #remove_digits\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[0-9]', \"\", regex=True)\n",
    "    \n",
    "    #remove stopwords and words_to_remove\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    mystopwords = [stop_words, \"via\", words_to_remove]\n",
    "    \n",
    "    df['fully_cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in mystopwords]))\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "#get the processed tweets\n",
    "df = cleantext(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets = cleantext(test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when  father  dysfunctional and   selfish  dr...</td>\n",
       "      <td>when father dysfunctional and selfish drags hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit  cant use cause they ...</td>\n",
       "      <td>thanks for lyft credit cant use cause they don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model    love  take with  all the time</td>\n",
       "      <td>model love take with all the time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>ate  isz that youuu</td>\n",
       "      <td>ate isz that youuu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>see nina turner  the airwaves trying  wrap he...</td>\n",
       "      <td>see nina turner the airwaves trying wrap herse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listening  sad songs   monday morning otw  wor...</td>\n",
       "      <td>listening sad songs monday morning otw work sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>sikh  temple vandalised    calgary  wso conde...</td>\n",
       "      <td>sikh temple vandalised calgary wso condemns act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank you  for you follow</td>\n",
       "      <td>thank you for you follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1      0   @user when a father is dysfunctional and is s...   \n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3      0                                bihday your majesty   \n",
       "3          4      0  #model   i love u take with u all the time in ...   \n",
       "4          5      0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...   \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...   \n",
       "31959  31960      0  listening to sad songs on a monday morning otw...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961  31962      0                   thank you @user for you follow     \n",
       "\n",
       "                                           cleaned_tweet  \\\n",
       "0       when  father  dysfunctional and   selfish  dr...   \n",
       "1       thanks for  lyft credit  cant use cause they ...   \n",
       "2                                    bihday your majesty   \n",
       "3                model    love  take with  all the time    \n",
       "4                 factsguide  society now     motivation   \n",
       "...                                                  ...   \n",
       "31957                               ate  isz that youuu    \n",
       "31958   see nina turner  the airwaves trying  wrap he...   \n",
       "31959  listening  sad songs   monday morning otw  wor...   \n",
       "31960   sikh  temple vandalised    calgary  wso conde...   \n",
       "31961                         thank you  for you follow    \n",
       "\n",
       "                                     fully_cleaned_tweet  \n",
       "0      when father dysfunctional and selfish drags hi...  \n",
       "1      thanks for lyft credit cant use cause they don...  \n",
       "2                                    bihday your majesty  \n",
       "3                      model love take with all the time  \n",
       "4                      factsguide society now motivation  \n",
       "...                                                  ...  \n",
       "31957                                 ate isz that youuu  \n",
       "31958  see nina turner the airwaves trying wrap herse...  \n",
       "31959    listening sad songs monday morning otw work sad  \n",
       "31960    sikh temple vandalised calgary wso condemns act  \n",
       "31961                           thank you for you follow  \n",
       "\n",
       "[31962 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when  father  dysfunctional and   selfish  dr...</td>\n",
       "      <td>when father dysfunctional and selfish drags hi...</td>\n",
       "      <td>[when, father, dysfunctional, and, selfish, dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit  cant use cause they ...</td>\n",
       "      <td>thanks for lyft credit cant use cause they don...</td>\n",
       "      <td>[thanks, for, lyft, credit, cant, use, cause, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model    love  take with  all the time</td>\n",
       "      <td>model love take with all the time</td>\n",
       "      <td>[model, love, take, with, all, the, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>ate  isz that youuu</td>\n",
       "      <td>ate isz that youuu</td>\n",
       "      <td>[ate, isz, that, youuu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>see nina turner  the airwaves trying  wrap he...</td>\n",
       "      <td>see nina turner the airwaves trying wrap herse...</td>\n",
       "      <td>[see, nina, turner, the, airwaves, trying, wra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listening  sad songs   monday morning otw  wor...</td>\n",
       "      <td>listening sad songs monday morning otw work sad</td>\n",
       "      <td>[listening, sad, songs, monday, morning, otw, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>sikh  temple vandalised    calgary  wso conde...</td>\n",
       "      <td>sikh temple vandalised calgary wso condemns act</td>\n",
       "      <td>[sikh, temple, vandalised, calgary, wso, conde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank you  for you follow</td>\n",
       "      <td>thank you for you follow</td>\n",
       "      <td>[thank, you, for, you, follow]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1      0   @user when a father is dysfunctional and is s...   \n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3      0                                bihday your majesty   \n",
       "3          4      0  #model   i love u take with u all the time in ...   \n",
       "4          5      0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...   \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...   \n",
       "31959  31960      0  listening to sad songs on a monday morning otw...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961  31962      0                   thank you @user for you follow     \n",
       "\n",
       "                                           cleaned_tweet  \\\n",
       "0       when  father  dysfunctional and   selfish  dr...   \n",
       "1       thanks for  lyft credit  cant use cause they ...   \n",
       "2                                    bihday your majesty   \n",
       "3                model    love  take with  all the time    \n",
       "4                 factsguide  society now     motivation   \n",
       "...                                                  ...   \n",
       "31957                               ate  isz that youuu    \n",
       "31958   see nina turner  the airwaves trying  wrap he...   \n",
       "31959  listening  sad songs   monday morning otw  wor...   \n",
       "31960   sikh  temple vandalised    calgary  wso conde...   \n",
       "31961                         thank you  for you follow    \n",
       "\n",
       "                                     fully_cleaned_tweet  \\\n",
       "0      when father dysfunctional and selfish drags hi...   \n",
       "1      thanks for lyft credit cant use cause they don...   \n",
       "2                                    bihday your majesty   \n",
       "3                      model love take with all the time   \n",
       "4                      factsguide society now motivation   \n",
       "...                                                  ...   \n",
       "31957                                 ate isz that youuu   \n",
       "31958  see nina turner the airwaves trying wrap herse...   \n",
       "31959    listening sad songs monday morning otw work sad   \n",
       "31960    sikh temple vandalised calgary wso condemns act   \n",
       "31961                           thank you for you follow   \n",
       "\n",
       "                                             tweet_token  \n",
       "0      [when, father, dysfunctional, and, selfish, dr...  \n",
       "1      [thanks, for, lyft, credit, cant, use, cause, ...  \n",
       "2                                [bihday, your, majesty]  \n",
       "3              [model, love, take, with, all, the, time]  \n",
       "4                 [factsguide, society, now, motivation]  \n",
       "...                                                  ...  \n",
       "31957                            [ate, isz, that, youuu]  \n",
       "31958  [see, nina, turner, the, airwaves, trying, wra...  \n",
       "31959  [listening, sad, songs, monday, morning, otw, ...  \n",
       "31960  [sikh, temple, vandalised, calgary, wso, conde...  \n",
       "31961                     [thank, you, for, you, follow]  \n",
       "\n",
       "[31962 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_token'] = df['fully_cleaned_tweet'].apply(word_tokenize)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets['tweet_token'] = test_tweets['fully_cleaned_tweet'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Words\n",
    "**We will use lemmatization, but we cannot do this without POS tagging, so created a function to return the lemmetizor tags and then return the lemma of the word list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    #return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v) \n",
    "        \n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "            # As default pos in lemmatization is Noun\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def pos_tag_1(tokens):\n",
    "        # find the pos tagginf for each tokens [('What', 'WP'), ('can', 'MD'), ('I', 'PRP') ....\n",
    "    lemma = []\n",
    "    for word, tag in pos_tag(tokens):\n",
    "        wntag = tag[0].lower()\n",
    "        wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "    #lemma = lemmatizer.lemmatize(word, wntag) \n",
    "        if not wntag:\n",
    "            lemma.append(word)\n",
    "        else:\n",
    "            lemma.append(lemmatizer.lemmatize(word, wntag))\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lemmatized'] = df.tweet_token.apply(lambda x: pos_tag_1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets['text_lemmatized'] = test_tweets.tweet_token.apply(lambda x: pos_tag_1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[when, father, dysfunctional, and, selfish, dr...</td>\n",
       "      <td>[when, father, dysfunctional, and, selfish, dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[thanks, for, lyft, credit, cant, use, cause, ...</td>\n",
       "      <td>[thanks, for, lyft, credit, cant, use, cause, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[model, love, take, with, all, the, time]</td>\n",
       "      <td>[model, love, take, with, all, the, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>[ate, isz, that, youuu]</td>\n",
       "      <td>[ate, isz, that, youuu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>[see, nina, turner, the, airwaves, trying, wra...</td>\n",
       "      <td>[see, nina, turner, the, airwave, try, wrap, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>[listening, sad, songs, monday, morning, otw, ...</td>\n",
       "      <td>[listen, sad, song, monday, morning, otw, work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>[sikh, temple, vandalised, calgary, wso, conde...</td>\n",
       "      <td>[sikh, temple, vandalise, calgary, wso, condem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>[thank, you, for, you, follow]</td>\n",
       "      <td>[thank, you, for, you, follow]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_token  \\\n",
       "0      [when, father, dysfunctional, and, selfish, dr...   \n",
       "1      [thanks, for, lyft, credit, cant, use, cause, ...   \n",
       "2                                [bihday, your, majesty]   \n",
       "3              [model, love, take, with, all, the, time]   \n",
       "4                 [factsguide, society, now, motivation]   \n",
       "...                                                  ...   \n",
       "31957                            [ate, isz, that, youuu]   \n",
       "31958  [see, nina, turner, the, airwaves, trying, wra...   \n",
       "31959  [listening, sad, songs, monday, morning, otw, ...   \n",
       "31960  [sikh, temple, vandalised, calgary, wso, conde...   \n",
       "31961                     [thank, you, for, you, follow]   \n",
       "\n",
       "                                         text_lemmatized  \n",
       "0      [when, father, dysfunctional, and, selfish, dr...  \n",
       "1      [thanks, for, lyft, credit, cant, use, cause, ...  \n",
       "2                                [bihday, your, majesty]  \n",
       "3              [model, love, take, with, all, the, time]  \n",
       "4                 [factsguide, society, now, motivation]  \n",
       "...                                                  ...  \n",
       "31957                            [ate, isz, that, youuu]  \n",
       "31958  [see, nina, turner, the, airwave, try, wrap, h...  \n",
       "31959  [listen, sad, song, monday, morning, otw, work...  \n",
       "31960  [sikh, temple, vandalise, calgary, wso, condem...  \n",
       "31961                     [thank, you, for, you, follow]  \n",
       "\n",
       "[31962 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['tweet_token','text_lemmatized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>when  father  dysfunctional and   selfish  dr...</td>\n",
       "      <td>when father dysfunctional and selfish drags hi...</td>\n",
       "      <td>[when, father, dysfunctional, and, selfish, dr...</td>\n",
       "      <td>[when, father, dysfunctional, and, selfish, dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks for  lyft credit  cant use cause they ...</td>\n",
       "      <td>thanks for lyft credit cant use cause they don...</td>\n",
       "      <td>[thanks, for, lyft, credit, cant, use, cause, ...</td>\n",
       "      <td>[thanks, for, lyft, credit, cant, use, cause, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>model    love  take with  all the time</td>\n",
       "      <td>model love take with all the time</td>\n",
       "      <td>[model, love, take, with, all, the, time]</td>\n",
       "      <td>[model, love, take, with, all, the, time]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>factsguide  society now     motivation</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate @user isz that youuu?ðððððð...</td>\n",
       "      <td>ate  isz that youuu</td>\n",
       "      <td>ate isz that youuu</td>\n",
       "      <td>[ate, isz, that, youuu]</td>\n",
       "      <td>[ate, isz, that, youuu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>to see nina turner on the airwaves trying to...</td>\n",
       "      <td>see nina turner  the airwaves trying  wrap he...</td>\n",
       "      <td>see nina turner the airwaves trying wrap herse...</td>\n",
       "      <td>[see, nina, turner, the, airwaves, trying, wra...</td>\n",
       "      <td>[see, nina, turner, the, airwave, try, wrap, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening to sad songs on a monday morning otw...</td>\n",
       "      <td>listening  sad songs   monday morning otw  wor...</td>\n",
       "      <td>listening sad songs monday morning otw work sad</td>\n",
       "      <td>[listening, sad, songs, monday, morning, otw, ...</td>\n",
       "      <td>[listen, sad, song, monday, morning, otw, work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>@user #sikh #temple vandalised in in #calgary,...</td>\n",
       "      <td>sikh  temple vandalised    calgary  wso conde...</td>\n",
       "      <td>sikh temple vandalised calgary wso condemns act</td>\n",
       "      <td>[sikh, temple, vandalised, calgary, wso, conde...</td>\n",
       "      <td>[sikh, temple, vandalise, calgary, wso, condem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you @user for you follow</td>\n",
       "      <td>thank you  for you follow</td>\n",
       "      <td>thank you for you follow</td>\n",
       "      <td>[thank, you, for, you, follow]</td>\n",
       "      <td>[thank, you, for, you, follow]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet  \\\n",
       "0          1      0   @user when a father is dysfunctional and is s...   \n",
       "1          2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2          3      0                                bihday your majesty   \n",
       "3          4      0  #model   i love u take with u all the time in ...   \n",
       "4          5      0             factsguide: society now    #motivation   \n",
       "...      ...    ...                                                ...   \n",
       "31957  31958      0  ate @user isz that youuu?ðððððð...   \n",
       "31958  31959      0    to see nina turner on the airwaves trying to...   \n",
       "31959  31960      0  listening to sad songs on a monday morning otw...   \n",
       "31960  31961      1  @user #sikh #temple vandalised in in #calgary,...   \n",
       "31961  31962      0                   thank you @user for you follow     \n",
       "\n",
       "                                           cleaned_tweet  \\\n",
       "0       when  father  dysfunctional and   selfish  dr...   \n",
       "1       thanks for  lyft credit  cant use cause they ...   \n",
       "2                                    bihday your majesty   \n",
       "3                model    love  take with  all the time    \n",
       "4                 factsguide  society now     motivation   \n",
       "...                                                  ...   \n",
       "31957                               ate  isz that youuu    \n",
       "31958   see nina turner  the airwaves trying  wrap he...   \n",
       "31959  listening  sad songs   monday morning otw  wor...   \n",
       "31960   sikh  temple vandalised    calgary  wso conde...   \n",
       "31961                         thank you  for you follow    \n",
       "\n",
       "                                     fully_cleaned_tweet  \\\n",
       "0      when father dysfunctional and selfish drags hi...   \n",
       "1      thanks for lyft credit cant use cause they don...   \n",
       "2                                    bihday your majesty   \n",
       "3                      model love take with all the time   \n",
       "4                      factsguide society now motivation   \n",
       "...                                                  ...   \n",
       "31957                                 ate isz that youuu   \n",
       "31958  see nina turner the airwaves trying wrap herse...   \n",
       "31959    listening sad songs monday morning otw work sad   \n",
       "31960    sikh temple vandalised calgary wso condemns act   \n",
       "31961                           thank you for you follow   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "0      [when, father, dysfunctional, and, selfish, dr...   \n",
       "1      [thanks, for, lyft, credit, cant, use, cause, ...   \n",
       "2                                [bihday, your, majesty]   \n",
       "3              [model, love, take, with, all, the, time]   \n",
       "4                 [factsguide, society, now, motivation]   \n",
       "...                                                  ...   \n",
       "31957                            [ate, isz, that, youuu]   \n",
       "31958  [see, nina, turner, the, airwaves, trying, wra...   \n",
       "31959  [listening, sad, songs, monday, morning, otw, ...   \n",
       "31960  [sikh, temple, vandalised, calgary, wso, conde...   \n",
       "31961                     [thank, you, for, you, follow]   \n",
       "\n",
       "                                         text_lemmatized  \n",
       "0      [when, father, dysfunctional, and, selfish, dr...  \n",
       "1      [thanks, for, lyft, credit, cant, use, cause, ...  \n",
       "2                                [bihday, your, majesty]  \n",
       "3              [model, love, take, with, all, the, time]  \n",
       "4                 [factsguide, society, now, motivation]  \n",
       "...                                                  ...  \n",
       "31957                            [ate, isz, that, youuu]  \n",
       "31958  [see, nina, turner, the, airwave, try, wrap, h...  \n",
       "31959  [listen, sad, song, monday, morning, otw, work...  \n",
       "31960  [sikh, temple, vandalise, calgary, wso, condem...  \n",
       "31961                     [thank, you, for, you, follow]  \n",
       "\n",
       "[31962 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['final_tweet'] = df['text_lemmatized'].apply(lambda x: ' '.join(word for word in x))\n",
    "test_tweets['final_tweet'] = test_tweets['text_lemmatized'].apply(lambda x: ' '.join(word for word in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[['final_tweet']]\n",
    "target = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train, target, test_size=0.3, random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22373, 1), (9589, 1), (22373,), (9589,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer(stop_words ='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = vec.fit_transform(train['final_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 35077)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_tfidf = vec.transform(x_val['final_tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9589, 35077)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<9589x35077 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 63313 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets_tfidf = vec.transform(test_tweets['final_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying ML Model - Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARIKA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf_log = LogisticRegression(random_state=2019, C=1000).fit(X_train_tfidf, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = clf_log.predict(x_val_tfidf)\n",
    "y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistics Regression F1 score :  99.88628756592658 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistics Regression F1 score : \",(f1_score(y_val,y_pred_val , average='macro'))*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets['label'] = clf_log.predict(test_tweets_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>tweet_token</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>final_tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>studiolife  aislife  requires  passion  dedic...</td>\n",
       "      <td>studiolife aislife requires passion dedication...</td>\n",
       "      <td>[studiolife, aislife, requires, passion, dedic...</td>\n",
       "      <td>[studiolife, aislife, require, passion, dedica...</td>\n",
       "      <td>studiolife aislife require passion dedication ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>white  supremacists want everyone  see the ne...</td>\n",
       "      <td>white supremacists want everyone see the new b...</td>\n",
       "      <td>[white, supremacists, want, everyone, see, the...</td>\n",
       "      <td>[white, supremacist, want, everyone, see, the,...</td>\n",
       "      <td>white supremacist want everyone see the new bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>safe ways  heal your  acne       altwaystoheal...</td>\n",
       "      <td>safe ways heal your acne altwaystoheal healthy...</td>\n",
       "      <td>[safe, ways, heal, your, acne, altwaystoheal, ...</td>\n",
       "      <td>[safe, way, heal, your, acne, altwaystoheal, h...</td>\n",
       "      <td>safe way heal your acne altwaystoheal healthy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>the  and the cursed child book  for reservati...</td>\n",
       "      <td>the and the cursed child book for reservations...</td>\n",
       "      <td>[the, and, the, cursed, child, book, for, rese...</td>\n",
       "      <td>[the, and, the, cursed, child, book, for, rese...</td>\n",
       "      <td>the and the cursed child book for reservation ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>rd  bihday   amazing hilarious  nephew eli ah...</td>\n",
       "      <td>rd bihday amazing hilarious nephew eli ahmir u...</td>\n",
       "      <td>[rd, bihday, amazing, hilarious, nephew, eli, ...</td>\n",
       "      <td>[rd, bihday, amaze, hilarious, nephew, eli, ah...</td>\n",
       "      <td>rd bihday amaze hilarious nephew eli ahmir unc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17192</th>\n",
       "      <td>49155</td>\n",
       "      <td>thought factory: left-right polarisation! #tru...</td>\n",
       "      <td>thought factory  leftright polarisation   trum...</td>\n",
       "      <td>thought factory leftright polarisation trump u...</td>\n",
       "      <td>[thought, factory, leftright, polarisation, tr...</td>\n",
       "      <td>[thought, factory, leftright, polarisation, tr...</td>\n",
       "      <td>thought factory leftright polarisation trump u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17193</th>\n",
       "      <td>49156</td>\n",
       "      <td>feeling like a mermaid ð #hairflip #neverre...</td>\n",
       "      <td>feeling like  mermaid       hairflip  neverrea...</td>\n",
       "      <td>feeling like mermaid hairflip neverready forma...</td>\n",
       "      <td>[feeling, like, mermaid, hairflip, neverready,...</td>\n",
       "      <td>[feel, like, mermaid, hairflip, neverready, fo...</td>\n",
       "      <td>feel like mermaid hairflip neverready formal w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17194</th>\n",
       "      <td>49157</td>\n",
       "      <td>#hillary #campaigned today in #ohio((omg)) &amp;am...</td>\n",
       "      <td>hillary  caigned today   ohioomg    used word...</td>\n",
       "      <td>hillary caigned today ohioomg used words like ...</td>\n",
       "      <td>[hillary, caigned, today, ohioomg, used, words...</td>\n",
       "      <td>[hillary, caigned, today, ohioomg, use, word, ...</td>\n",
       "      <td>hillary caigned today ohioomg use word like as...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <td>49158</td>\n",
       "      <td>happy, at work conference: right mindset leads...</td>\n",
       "      <td>happy  work conference  right mindset leads  c...</td>\n",
       "      <td>happy work conference right mindset leads cult...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "      <td>[happy, work, conference, right, mindset, lead...</td>\n",
       "      <td>happy work conference right mindset lead cultu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17196</th>\n",
       "      <td>49159</td>\n",
       "      <td>my   song \"so glad\" free download!  #shoegaze ...</td>\n",
       "      <td>song  glad free download    shoegaze  newmusi...</td>\n",
       "      <td>song glad free download shoegaze newmusic newsong</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "      <td>[song, glad, free, download, shoegaze, newmusi...</td>\n",
       "      <td>song glad free download shoegaze newmusic newsong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17197 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              tweet  \\\n",
       "0      31963  #studiolife #aislife #requires #passion #dedic...   \n",
       "1      31964   @user #white #supremacists want everyone to s...   \n",
       "2      31965  safe ways to heal your #acne!!    #altwaystohe...   \n",
       "3      31966  is the hp and the cursed child book up for res...   \n",
       "4      31967    3rd #bihday to my amazing, hilarious #nephew...   \n",
       "...      ...                                                ...   \n",
       "17192  49155  thought factory: left-right polarisation! #tru...   \n",
       "17193  49156  feeling like a mermaid ð #hairflip #neverre...   \n",
       "17194  49157  #hillary #campaigned today in #ohio((omg)) &am...   \n",
       "17195  49158  happy, at work conference: right mindset leads...   \n",
       "17196  49159  my   song \"so glad\" free download!  #shoegaze ...   \n",
       "\n",
       "                                           cleaned_tweet  \\\n",
       "0       studiolife  aislife  requires  passion  dedic...   \n",
       "1       white  supremacists want everyone  see the ne...   \n",
       "2      safe ways  heal your  acne       altwaystoheal...   \n",
       "3       the  and the cursed child book  for reservati...   \n",
       "4       rd  bihday   amazing hilarious  nephew eli ah...   \n",
       "...                                                  ...   \n",
       "17192  thought factory  leftright polarisation   trum...   \n",
       "17193  feeling like  mermaid       hairflip  neverrea...   \n",
       "17194   hillary  caigned today   ohioomg    used word...   \n",
       "17195  happy  work conference  right mindset leads  c...   \n",
       "17196   song  glad free download    shoegaze  newmusi...   \n",
       "\n",
       "                                     fully_cleaned_tweet  \\\n",
       "0      studiolife aislife requires passion dedication...   \n",
       "1      white supremacists want everyone see the new b...   \n",
       "2      safe ways heal your acne altwaystoheal healthy...   \n",
       "3      the and the cursed child book for reservations...   \n",
       "4      rd bihday amazing hilarious nephew eli ahmir u...   \n",
       "...                                                  ...   \n",
       "17192  thought factory leftright polarisation trump u...   \n",
       "17193  feeling like mermaid hairflip neverready forma...   \n",
       "17194  hillary caigned today ohioomg used words like ...   \n",
       "17195  happy work conference right mindset leads cult...   \n",
       "17196  song glad free download shoegaze newmusic newsong   \n",
       "\n",
       "                                             tweet_token  \\\n",
       "0      [studiolife, aislife, requires, passion, dedic...   \n",
       "1      [white, supremacists, want, everyone, see, the...   \n",
       "2      [safe, ways, heal, your, acne, altwaystoheal, ...   \n",
       "3      [the, and, the, cursed, child, book, for, rese...   \n",
       "4      [rd, bihday, amazing, hilarious, nephew, eli, ...   \n",
       "...                                                  ...   \n",
       "17192  [thought, factory, leftright, polarisation, tr...   \n",
       "17193  [feeling, like, mermaid, hairflip, neverready,...   \n",
       "17194  [hillary, caigned, today, ohioomg, used, words...   \n",
       "17195  [happy, work, conference, right, mindset, lead...   \n",
       "17196  [song, glad, free, download, shoegaze, newmusi...   \n",
       "\n",
       "                                         text_lemmatized  \\\n",
       "0      [studiolife, aislife, require, passion, dedica...   \n",
       "1      [white, supremacist, want, everyone, see, the,...   \n",
       "2      [safe, way, heal, your, acne, altwaystoheal, h...   \n",
       "3      [the, and, the, cursed, child, book, for, rese...   \n",
       "4      [rd, bihday, amaze, hilarious, nephew, eli, ah...   \n",
       "...                                                  ...   \n",
       "17192  [thought, factory, leftright, polarisation, tr...   \n",
       "17193  [feel, like, mermaid, hairflip, neverready, fo...   \n",
       "17194  [hillary, caigned, today, ohioomg, use, word, ...   \n",
       "17195  [happy, work, conference, right, mindset, lead...   \n",
       "17196  [song, glad, free, download, shoegaze, newmusi...   \n",
       "\n",
       "                                             final_tweet  label  \n",
       "0      studiolife aislife require passion dedication ...      0  \n",
       "1      white supremacist want everyone see the new bi...      0  \n",
       "2      safe way heal your acne altwaystoheal healthy ...      0  \n",
       "3      the and the cursed child book for reservation ...      0  \n",
       "4      rd bihday amaze hilarious nephew eli ahmir unc...      0  \n",
       "...                                                  ...    ...  \n",
       "17192  thought factory leftright polarisation trump u...      1  \n",
       "17193  feel like mermaid hairflip neverready formal w...      0  \n",
       "17194  hillary caigned today ohioomg use word like as...      0  \n",
       "17195  happy work conference right mindset lead cultu...      0  \n",
       "17196  song glad free download shoegaze newmusic newsong      0  \n",
       "\n",
       "[17197 rows x 8 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweets = test_tweets[['id','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweets.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
